{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eec946cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "from konlpy.tag import Okt\n",
    "from bs4 import BeautifulSoup\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4315f169",
   "metadata": {},
   "source": [
    "# LSTM 학습 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b357bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(symbol):\n",
    "    krx = pd.read_csv('./src/krx_code.csv')\n",
    "    krx = krx.set_index('한글 종목약명')\n",
    "    try:\n",
    "        code = krx.at[symbol,'단축코드']\n",
    "        return code\n",
    "    except:\n",
    "        print('종목명을 다시 확인해주세요.')\n",
    "        return 0\n",
    "\n",
    "def get_comment_df(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    code = get_code(symbol)\n",
    "    date_list, comment_list, view_list, good_list, bad_list = [], [], [], [], []\n",
    "    for i in range(1,page+1):\n",
    "        url = f'https://finance.naver.com/item/board.naver?code={code}&page={i}'\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50'}\n",
    "        res = requests.get(url, headers = headers)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')\n",
    "        for j in range(20):\n",
    "            try:\n",
    "                root = bs.find('div',{'class':'section inner_sub'}).find_all('tr',{'onmouseover':'mouseOver(this)'})[j].text.split('\\n')\n",
    "                date_list.append(root[1].split()[0].replace('.','-'))\n",
    "                if len(root) == 14: # 답글\n",
    "                    comment_list.append('답글:'+root[4])\n",
    "                    view_list.append(root[10])\n",
    "                    good_list.append(root[11])\n",
    "                    bad_list.append(root[12])          \n",
    "                elif len(root) == 13: # 기본\n",
    "                    comment_list.append(root[3])\n",
    "                    view_list.append(root[9])\n",
    "                    good_list.append(root[10])\n",
    "                    bad_list.append(root[11])\n",
    "                else: # 에러\n",
    "                    comment_list.append('error')\n",
    "                    view_list.append(0)\n",
    "                    good_list.append(0)\n",
    "                    bad_list.append(0)   \n",
    "            except: # 에러\n",
    "                date_list.append('error')\n",
    "                comment_list.append('error')\n",
    "                view_list.append(0)\n",
    "                good_list.append(0)\n",
    "                bad_list.append(0)   \n",
    "        print(f'\\r{i}페이지 크롤링 완료.',end='')   \n",
    "    df = pd.DataFrame()\n",
    "    df['날짜'] = date_list\n",
    "    df['댓글'] = comment_list\n",
    "    df['조회수'] = view_list\n",
    "    df['좋아요'] = good_list\n",
    "    df['싫어요'] = bad_list\n",
    "    return df\n",
    "\n",
    "def preprocess_df(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return \n",
    "    df = get_comment_df(symbol,page)\n",
    "    df = df[df['댓글'] != 'error'] \n",
    "    df = df.dropna() \n",
    "    df['한글댓글'] = df['댓글'].str.replace('\\[삭제된 게시물의 답글\\]',' ') \n",
    "    df['한글댓글'] = df['한글댓글'].str.replace('답글:',' ')\n",
    "    df['한글댓글'] = df['한글댓글'].str.replace('[^가-힣]',' ').str.replace(' +',' ').str.strip() \n",
    "    df = df[df['한글댓글'] != ''] \n",
    "    df = df.reset_index(drop=True) \n",
    "    return df\n",
    "\n",
    "def preprocess_okt_df(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    df = preprocess_df(symbol,page)\n",
    "    okt = Okt()\n",
    "    tag_list = ['Noun','Verb','Adjective','VerbPrefix']\n",
    "    tokenized_data = []\n",
    "    print()\n",
    "    for i in range(df.shape[0]):\n",
    "        tokenized_sentence = okt.pos(df['한글댓글'][i], stem=True) # 토큰화\n",
    "        tag_checked_sentence = []\n",
    "        for j in tokenized_sentence:\n",
    "            x,y = j\n",
    "            if y in tag_list:\n",
    "                tag_checked_sentence.append(x)\n",
    "        tokenized_data.append(tag_checked_sentence)\n",
    "        print(f'\\r{i+1}개 형태소분석 완료',end='')\n",
    "    df['토큰화댓글'] = tokenized_data\n",
    "    df = df[df['토큰화댓글'].str.len() > 1]\n",
    "    df = df.reset_index(drop=True) \n",
    "    return df\n",
    "\n",
    "greed_word = ['매수','사','사다','사라','사면','사고','줍다','들어오다','들어가다','타다','수급','매집','올라타다' # 주식 구매 단어\n",
    "              ,'탑승','불나방','담다'\n",
    "              ,'오르다','올라가다','올리다','올려주다','올린다','오름','올려놓다','오른','상향' # 주식 가격 상승 단어\n",
    "              ,'양봉','상방','상승','살아나다','양전','상한','반등','폭등','퍽등','급등'\n",
    "              ,'탐욕','찬티','좋다','간다','가다','가즈','싸다','익절','제발','최고','돌파','수익','위대하다','먹다' # 탐욕 단어\n",
    "              ,'기회','호재','감사','감사하다','대박','대단하다','승리','찬양','믿다','회복','갓','부활','영차','개꿀']\n",
    "fear_word = ['공매도','공매','매도','팔','파다','팔다','팔고','팔면','던지다','털다','탈출','튀다','튀어','설거지' # 주식 판매 단어\n",
    "             ,'손절','버리다'\n",
    "             ,'떨어지다','떨구다','빠지다','하락','폭락','떡락','조정','급락','음봉','하방','폭포수','음전' # 주식 가격 하락 단어\n",
    "             ,'반토막','내리다','내려오다','깨지다','대퍽락','나락','붕괴','추락'\n",
    "             ,'공포','안티','망하다','물리다','끝나다','손해','폭망','거품','무섭다','자살','악재','상폐','개미지옥' # 공포 단어\n",
    "             ,'시발','염병','욕','짜증나다','걸레','어휴','개','놈','아가리','빡치다','지랄','손실','버티다','존버'\n",
    "             ,'개관','주가조작','쓰레기','죽다','패닉','홀딩','바닥','흑우','추매','추미애']\n",
    "\n",
    "def preprocess_label_df(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    df = preprocess_okt_df(symbol,page)\n",
    "    df['공포탐욕'] = 0\n",
    "    label_list = df['공포탐욕'].to_list()\n",
    "    token_list = df['토큰화댓글'].to_list()\n",
    "    print()\n",
    "    for i in range(len(token_list)):\n",
    "        x = token_list[i]\n",
    "        for word in x:\n",
    "            if word in greed_word:\n",
    "                label_list[i] += 1\n",
    "            if word in fear_word:\n",
    "                label_list[i] -= 1\n",
    "        if label_list[i] == 0:\n",
    "            label_list[i] = 'm'\n",
    "        elif label_list[i] > 0:\n",
    "            label_list[i] = 1\n",
    "        elif label_list[i] < 0:\n",
    "            label_list[i] = 0\n",
    "        print(f'\\r{i+1}개 라벨링 완료',end='')\n",
    "    df['공포탐욕'] = label_list\n",
    "    df.to_csv(f'./src/네이버종토방댓글_{symbol}_{page}_전처리.csv', index=False)\n",
    "    return df\n",
    "\n",
    "def make_train(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    train = pd.read_csv('./src/train.csv')\n",
    "    train = train[['토큰화댓글','공포탐욕']]\n",
    "    df = preprocess_label_df(symbol,page)\n",
    "    df = df[['토큰화댓글','공포탐욕']]\n",
    "    df = df.append(train)\n",
    "    df = df.astype(str)\n",
    "    df = df.drop_duplicates('토큰화댓글')\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def make_train_token(symbol,page):\n",
    "    if get_code(symbol) == 0:\n",
    "        return\n",
    "    df = make_train(symbol,page)\n",
    "    print()\n",
    "    print('토큰화 진행중..',end='')\n",
    "    tokenizer = Tokenizer(num_words=40000, oov_token = True)\n",
    "    tokenizer.fit_on_texts(df['토큰화댓글'])\n",
    "    df['토큰'] = tokenizer.texts_to_sequences(df['토큰화댓글'])\n",
    "    print('\\r토큰화 완료.    ')\n",
    "    with open('./src/tokenizer.pickle', 'wb') as handle:\n",
    "        pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    df = df[df['공포탐욕'] != 'm']\n",
    "    df = df.reset_index(drop=True)\n",
    "    df.to_csv(f'./src/train.csv', index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d5ae80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_train_token('NAVER',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb36279",
   "metadata": {},
   "source": [
    "# LSTM 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29b07473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_LSTM():\n",
    "    df = pd.read_csv('./src/train.csv')\n",
    "    train = pad_sequences(df['토큰'], maxlen=15)\n",
    "    \n",
    "    label = df['공포탐욕']\n",
    "    encoder = LabelEncoder()\n",
    "    batch_size = label.shape[0]\n",
    "    input_dim = 1\n",
    "    label = encoder.fit_transform(label)\n",
    "    label = np.reshape(label, (batch_size, input_dim))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(30000, 128))\n",
    "    model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    hist = model.fit(train, label, batch_size=32, epochs=5)\n",
    "    model.save('./src/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0392f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_LSTM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
