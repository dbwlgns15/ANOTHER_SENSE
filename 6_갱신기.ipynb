{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde6fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5550ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# LSTM 토크나이저\n",
    "with open('./src/lstm/goodtokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)  \n",
    "# LSTM 모델\n",
    "model = load_model('./src/lstm/goodmodel.h5')\n",
    "# BERT 토크나이저, 모델\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained('./src/bert', from_pt=True)\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained('./src/bert', from_pt=True)\n",
    "classifier = TextClassificationPipeline(tokenizer=loaded_tokenizer, model=loaded_model,\n",
    "                                            framework='tf', return_all_scores=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f51b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(symbol):\n",
    "    krx = pd.read_csv('./src/krx_code.csv')\n",
    "    krx = krx.set_index('한글 종목약명')\n",
    "    try:\n",
    "        code = krx.at[symbol,'단축코드']\n",
    "        return code\n",
    "    except:\n",
    "        print('종목명을 다시 확인해주세요.')\n",
    "        return 0\n",
    "\n",
    "def get_comment(df,symbol):\n",
    "    code = get_code(symbol)\n",
    "    day = df['날짜'][0]\n",
    "    date_list = []\n",
    "    comment_list = []\n",
    "    raw_comment_list = []\n",
    "    chk = 1\n",
    "    i = 1\n",
    "    while chk:  \n",
    "        url = f'https://finance.naver.com/item/board.naver?code={code}&page={i}'\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50'}\n",
    "        res = requests.get(url, headers = headers)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')  \n",
    "        for j in range(20):\n",
    "            try:\n",
    "                root = bs.find('div',{'class':'section inner_sub'}).find_all('tr',{'onmouseover':'mouseOver(this)'})[j].text.split('\\n')                 \n",
    "                if day > root[1].split()[0].replace('.','-'):\n",
    "                    chk = 0\n",
    "                    break\n",
    "                if len(root) == 14: # 답글\n",
    "                    pass      \n",
    "                elif len(root) == 13: # 기본\n",
    "                    comment = root[3]\n",
    "                    date_list.append(root[1].split()[0].replace('.','-'))\n",
    "                    raw_comment_list.append(comment)            \n",
    "                else: # 에러\n",
    "                    pass\n",
    "            except: # 에러\n",
    "                pass\n",
    "            print(f'\\r{day} 댓글{len(raw_comment_list)}개 크롤링중..',end='')\n",
    "        i += 1\n",
    "        if chk == 0:\n",
    "            break   \n",
    "    print(f'\\r{day} 댓글{len(raw_comment_list)}개 크롤링완료')\n",
    "    df = pd.DataFrame()\n",
    "    df['날짜'] = date_list\n",
    "    df['댓글'] = raw_comment_list\n",
    "    return df\n",
    "\n",
    "def BERT_feargreed(df,symbol):\n",
    "    df = get_comment(df,symbol)  \n",
    "    raw_comment_list = df['댓글'].to_list()\n",
    "    pred_list=[]\n",
    "    for i in raw_comment_list:\n",
    "        a = classifier(i)[0]\n",
    "        f = a[0]['score']\n",
    "        g = a[1]['score']\n",
    "        if f >= g:\n",
    "            pred_list.append(1-f)\n",
    "        else:\n",
    "            pred_list.append(g)\n",
    "        print(f'\\rBERT 댓글{len(pred_list)}개 분석중..',end='')\n",
    "    df['BERT'] = pred_list  \n",
    "    return df\n",
    "\n",
    "def konlpy_okt(df,symbol):\n",
    "    df = BERT_feargreed(df,symbol)\n",
    "    okt = Okt()\n",
    "    tag_list = ['Noun','Verb','Adjective','VerbPrefix'] \n",
    "    comment_list = df['댓글'].to_list()\n",
    "    tokenized_data = []\n",
    "    for i in range(len(comment_list)):\n",
    "        tokenized_sentence = okt.pos(comment_list[i], stem=True) \n",
    "        tag_checked_sentence = []\n",
    "        for j in tokenized_sentence:\n",
    "            x,y = j\n",
    "            if y in tag_list:\n",
    "                tag_checked_sentence.append(x)\n",
    "        tokenized_data.append(tag_checked_sentence)     \n",
    "    for i in tokenized_data:\n",
    "        for j in range(len(i)):\n",
    "            i[j] = \"'\"+i[j]+\"'\"\n",
    "    df['LSTM'] = tokenized_data\n",
    "    return df\n",
    "    \n",
    "def feargreed_index(df,symbol):\n",
    "    df = konlpy_okt(df,symbol)\n",
    "    tokenized_data = df['LSTM'].to_list()\n",
    "    test = tokenizer.texts_to_sequences(tokenized_data)\n",
    "    test = pad_sequences(test, maxlen=15)\n",
    "    pred = model.predict(test)\n",
    "    df['LSTM'] = pred\n",
    "    df['LSTM'] = df['LSTM'].round(6)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c13a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-29 댓글48개 크롤링완료.\n",
      "BERT 댓글48개 분석중.."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>댓글</th>\n",
       "      <th>BERT</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>현대</td>\n",
       "      <td>0.883406</td>\n",
       "      <td>0.492446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>잘놀다갑니다~</td>\n",
       "      <td>0.579546</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>ㅋㅋ 미치것네</td>\n",
       "      <td>0.630709</td>\n",
       "      <td>0.131151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>지금 확실히 중요한데..</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.006648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>오늘은 네이버가 1등이다 1등</td>\n",
       "      <td>0.635175</td>\n",
       "      <td>0.008385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9469</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>어르신들 .</td>\n",
       "      <td>0.404791</td>\n",
       "      <td>0.030063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9470</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>차트는 좋네</td>\n",
       "      <td>0.153072</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9471</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>[잘쳐먹고잘산다는미명하에 온갖곳에 악질이...</td>\n",
       "      <td>0.706786</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9472</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>●●●● 찢재명,,, 왈 ~~</td>\n",
       "      <td>0.845221</td>\n",
       "      <td>0.104308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9473</th>\n",
       "      <td>2022-03-01</td>\n",
       "      <td>정권교체해도 바뀌...</td>\n",
       "      <td>0.201146</td>\n",
       "      <td>0.104928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9474 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              날짜                         댓글      BERT      LSTM\n",
       "0     2022-05-30                         현대  0.883406  0.492446\n",
       "1     2022-05-30                    잘놀다갑니다~  0.579546  1.000000\n",
       "2     2022-05-30                    ㅋㅋ 미치것네  0.630709  0.131151\n",
       "3     2022-05-30              지금 확실히 중요한데..  0.689900  0.006648\n",
       "4     2022-05-30           오늘은 네이버가 1등이다 1등  0.635175  0.008385\n",
       "...          ...                        ...       ...       ...\n",
       "9469  2022-03-01                     어르신들 .  0.404791  0.030063\n",
       "9470  2022-03-01                     차트는 좋네  0.153072  1.000000\n",
       "9471  2022-03-01  [잘쳐먹고잘산다는미명하에 온갖곳에 악질이...  0.706786  1.000000\n",
       "9472  2022-03-01           ●●●● 찢재명,,, 왈 ~~  0.845221  0.104308\n",
       "9473  2022-03-01               정권교체해도 바뀌...  0.201146  0.104928\n",
       "\n",
       "[9474 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./src/score_naver_0301.csv')\n",
    "df2 = feargreed_index(df,'NAVER')\n",
    "df_naver = df2.append(df).drop_duplicates(subset=['날짜','댓글'],keep='last')\n",
    "df_naver = df_naver.reset_index(drop=True)\n",
    "df_naver.to_csv('./src/score_naver_0301.csv',index=False)\n",
    "df_naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0df1c936",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-29 댓글66개 크롤링완료.\n",
      "BERT 댓글66개 분석중.."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>댓글</th>\n",
       "      <th>BERT</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>네이버가 1등 카카오가 2 등이다</td>\n",
       "      <td>0.598076</td>\n",
       "      <td>0.050569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>대붕괴의  시대</td>\n",
       "      <td>0.108117</td>\n",
       "      <td>0.663647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>카카오 상장하나 더하자 5만원 까지 하방...</td>\n",
       "      <td>0.032603</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>\" 앵두나무 \" 1004 호구들 레버리지...</td>\n",
       "      <td>0.328810</td>\n",
       "      <td>0.050140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-30</td>\n",
       "      <td>나스닥 장 전체가 10퍼 가까이 오르는데...</td>\n",
       "      <td>0.178061</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49491</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>잡주에 물린게 한이다</td>\n",
       "      <td>0.135482</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49492</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>외국인기관=쌍끌이양매수~바닥찍고V급등</td>\n",
       "      <td>0.033352</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49493</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>카카오는 주가부양  대책없냐?</td>\n",
       "      <td>0.099854</td>\n",
       "      <td>0.890823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49494</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>디카르고가 진카입니다</td>\n",
       "      <td>0.877022</td>\n",
       "      <td>0.653434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49495</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>플랫폼 사업이 해외 진출을 기대하 건 개...</td>\n",
       "      <td>0.044399</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>49496 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               날짜                         댓글      BERT      LSTM\n",
       "0      2022-05-30         네이버가 1등 카카오가 2 등이다  0.598076  0.050569\n",
       "1      2022-05-30                   대붕괴의  시대  0.108117  0.663647\n",
       "2      2022-05-30  카카오 상장하나 더하자 5만원 까지 하방...  0.032603  0.000000\n",
       "3      2022-05-30  \" 앵두나무 \" 1004 호구들 레버리지...  0.328810  0.050140\n",
       "4      2022-05-30  나스닥 장 전체가 10퍼 가까이 오르는데...  0.178061  1.000000\n",
       "...           ...                        ...       ...       ...\n",
       "49491  2021-11-01                잡주에 물린게 한이다  0.135482  0.000000\n",
       "49492  2021-11-01       외국인기관=쌍끌이양매수~바닥찍고V급등  0.033352  1.000000\n",
       "49493  2021-11-01           카카오는 주가부양  대책없냐?  0.099854  0.890823\n",
       "49494  2021-11-01                디카르고가 진카입니다  0.877022  0.653434\n",
       "49495  2021-11-01  플랫폼 사업이 해외 진출을 기대하 건 개...  0.044399  0.000000\n",
       "\n",
       "[49496 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./src/score_kakao_1101.csv')\n",
    "df2 = feargreed_index(df,'카카오')\n",
    "df_kakao = df2.append(df).drop_duplicates(subset=['날짜','댓글'],keep='last')\n",
    "df_kakao = df_kakao.reset_index(drop=True)\n",
    "df_kakao.to_csv('./src/score_kakao_1101.csv',index=False)\n",
    "df_kakao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60422126",
   "metadata": {},
   "outputs": [],
   "source": [
    "def konlpy_okt(df):\n",
    "    okt = Okt()\n",
    "    tag_list = ['Noun','Verb','Adjective','VerbPrefix'] \n",
    "    comment_list = df['댓글'].to_list()\n",
    "    tokenized_data = []\n",
    "    for i in range(len(comment_list)):\n",
    "        tokenized_sentence = okt.pos(str(comment_list[i]), stem=True) \n",
    "        tag_checked_sentence = []\n",
    "        for j in tokenized_sentence:\n",
    "            x,y = j\n",
    "            if y in tag_list:\n",
    "                tag_checked_sentence.append(x)\n",
    "        tokenized_data.append(tag_checked_sentence)   \n",
    "        print(f'\\r{i+1}개 형태소분리중',end='')\n",
    "    for i in tokenized_data:\n",
    "        for j in range(len(i)):\n",
    "            i[j] = \"'\"+i[j]+\"'\"\n",
    "    return tokenized_data\n",
    "    \n",
    "def tokenize(df):\n",
    "    tokenized_data = konlpy_okt(df)\n",
    "    test = tokenizer.texts_to_sequences(tokenized_data)\n",
    "    test = pad_sequences(test, maxlen=15)\n",
    "    return test\n",
    "\n",
    "def feargreed_indexx(df): \n",
    "    test = tokenize(df)\n",
    "    pred = model.predict(test)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c4ba811",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LSTM'] = feargreed_indexx(df)\n",
    "df['LSTM'] = df['LSTM'].round(6)\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9915e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
