{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde6fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5550ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# LSTM 토크나이저\n",
    "with open('./src/lstm/goodtokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)  \n",
    "# LSTM 모델\n",
    "model = load_model('./src/lstm/goodmodel.h5')\n",
    "# BERT 토크나이저, 모델\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained('./src/bert', from_pt=True)\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained('./src/bert', from_pt=True)\n",
    "classifier = TextClassificationPipeline(tokenizer=loaded_tokenizer, model=loaded_model,\n",
    "                                            framework='tf', return_all_scores=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "15f51b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_comment_csv():\n",
    "    df_naver = pd.read_csv('./streamlit/data/feargreed_naver.csv')\n",
    "    df_kakao = pd.read_csv('./streamlit/data/feargreed_kakao.csv')\n",
    "    return df_naver, df_kakao\n",
    "\n",
    "def get_code(symbol):\n",
    "    if symbol == '카카오':\n",
    "        code = '035720' # 카카오\n",
    "    else:\n",
    "        code = '035420' # NAVER\n",
    "    return code\n",
    "\n",
    "def get_comment(df,symbol):\n",
    "    code = get_code(symbol)\n",
    "    day = df['날짜'][0]\n",
    "    date_list = []\n",
    "    comment_list = []\n",
    "    raw_comment_list = []\n",
    "    chk = 1\n",
    "    i = 1\n",
    "    while chk:  \n",
    "        url = f'https://finance.naver.com/item/board.naver?code={code}&page={i}'\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50'}\n",
    "        res = requests.get(url, headers = headers)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')  \n",
    "        for j in range(20):\n",
    "            try:\n",
    "                root = bs.find('div',{'class':'section inner_sub'}).find_all('tr',{'onmouseover':'mouseOver(this)'})[j].text.split('\\n')                 \n",
    "                if day > root[1].split()[0].replace('.','-'):\n",
    "                    chk = 0\n",
    "                    break\n",
    "                if len(root) == 14: # 답글\n",
    "                    pass      \n",
    "                elif len(root) == 13: # 기본\n",
    "                    comment = root[3]\n",
    "                    date_list.append(root[1].split()[0].replace('.','-'))\n",
    "                    raw_comment_list.append(comment)            \n",
    "                else: # 에러\n",
    "                    pass\n",
    "            except: # 에러\n",
    "                pass\n",
    "            print(f'\\r{day} 댓글{len(raw_comment_list)}개 크롤링중..',end='')\n",
    "        i += 1\n",
    "        if chk == 0:\n",
    "            break   \n",
    "    print(f'\\r{day} 댓글{len(raw_comment_list)}개 크롤링완료')\n",
    "    df = pd.DataFrame()\n",
    "    df['날짜'] = date_list\n",
    "    df['댓글'] = raw_comment_list\n",
    "    return df\n",
    "\n",
    "def BERT_feargreed(df,symbol):\n",
    "    df = get_comment(df,symbol)  \n",
    "    raw_comment_list = df['댓글'].to_list()\n",
    "    pred_list=[]\n",
    "    for i in raw_comment_list:\n",
    "        a = classifier(i)[0]\n",
    "        f = a[0]['score']\n",
    "        g = a[1]['score']\n",
    "        if f >= g:\n",
    "            pred_list.append(1-f)\n",
    "        else:\n",
    "            pred_list.append(g)\n",
    "        print(f'\\rBERT 댓글{len(pred_list)}개 분석중..',end='')\n",
    "    df['BERT'] = pred_list  \n",
    "    print('BERT분석 완료.')\n",
    "    return df\n",
    "\n",
    "def konlpy_okt(df,symbol):\n",
    "    df = BERT_feargreed(df,symbol)\n",
    "    okt = Okt()\n",
    "    tag_list = ['Noun','Verb','Adjective','VerbPrefix'] \n",
    "    comment_list = df['댓글'].to_list()\n",
    "    tokenized_data = []\n",
    "    for i in range(len(comment_list)):\n",
    "        tokenized_sentence = okt.pos(comment_list[i], stem=True) \n",
    "        tag_checked_sentence = []\n",
    "        for j in tokenized_sentence:\n",
    "            x,y = j\n",
    "            if y in tag_list:\n",
    "                tag_checked_sentence.append(x)\n",
    "        tokenized_data.append(tag_checked_sentence)     \n",
    "    for i in tokenized_data:\n",
    "        for j in range(len(i)):\n",
    "            i[j] = \"'\"+i[j]+\"'\"\n",
    "    df['LSTM'] = tokenized_data\n",
    "    return df\n",
    "    \n",
    "def feargreed_index(df,symbol):\n",
    "    df = konlpy_okt(df,symbol)\n",
    "    tokenized_data = df['LSTM'].to_list()\n",
    "    test = tokenizer.texts_to_sequences(tokenized_data)\n",
    "    test = pad_sequences(test, maxlen=15)\n",
    "    pred = model.predict(test)\n",
    "    df['LSTM'] = pred\n",
    "    df['LSTM'] = df['LSTM'].round(6)\n",
    "    print('LSTM분석 완료.')\n",
    "    return df\n",
    "\n",
    "def update_comment():\n",
    "    df_naver, df_kakao = read_comment_csv()\n",
    "    \n",
    "    print('NAVER 댓글 갱신중...')\n",
    "    df2_naver = feargreed_index(df_naver,'NAVER')\n",
    "    df_naver = df2_naver.append(df_naver).drop_duplicates(subset=['날짜','댓글'],keep='last')\n",
    "    df_naver = df_naver.reset_index(drop=True)\n",
    "    print('NAVER 댓글 갱신완료.')\n",
    "    \n",
    "    print('카카오 댓글 갱신중...')\n",
    "    df2_kakao = feargreed_index(df_kakao,'카카오')\n",
    "    df_kakao = df2_kakao.append(df_kakao).drop_duplicates(subset=['날짜','댓글'],keep='last')\n",
    "    df_kakao = df_kakao.reset_index(drop=True)\n",
    "    print('카카오 댓글 갱신완료.')\n",
    "    \n",
    "    df_naver.to_csv('./streamlit/data/feargreed_naver.csv',index=False)\n",
    "    df_kakao.to_csv('./streamlit/data/feargreed_kakao.csv',index=False)  \n",
    "    return df_naver, df_kakao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57d5a9e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAVER 댓글 갱신중...\n",
      "2022-06-07 댓글104개 크롤링완료.\n",
      "BERT 댓글104개 분석중..BERT분석 완료.\n",
      "LSTM분석 완료.\n",
      "NAVER 댓글 갱신완료.\n",
      "카카오 댓글 갱신중...\n",
      "2022-06-07 댓글313개 크롤링완료.\n",
      "BERT 댓글313개 분석중..BERT분석 완료.\n",
      "LSTM분석 완료.\n",
      "카카오 댓글 갱신완료.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(               날짜                   댓글      BERT      LSTM\n",
       " 0      2022-06-07          오늘은 왜 내렸어요?  0.255915  0.000000\n",
       " 1      2022-06-07                   코닥  0.088301  0.711319\n",
       " 2      2022-06-07            어디를 뺐다는거야  0.101173  0.045362\n",
       " 3      2022-06-07       분할하던가 배당을 늘리던가  0.085969  0.994658\n",
       " 4      2022-06-07                 x수여니  0.801379  0.109405\n",
       " ...           ...                  ...       ...       ...\n",
       " 32651  2021-06-01              네이버 ㅋㅋㅋ  0.404388  0.014867\n",
       " 32652  2021-06-01         역시 네이버가 갑 !!  0.803849  0.392791\n",
       " 32653  2021-06-01  공매도 관련 전쟁 동영상 (한투연)  0.030869  0.000000\n",
       " 32654  2021-06-01         네이버 분들 오세요!!  0.690160  0.119831\n",
       " 32655  2021-06-01         네이버 주가예상 가즈아  0.617649  1.000000\n",
       " \n",
       " [32656 rows x 4 columns],\n",
       "                 날짜                         댓글      BERT      LSTM\n",
       " 0       2022-06-07                    일찍 좀 볼걸  0.295157  0.811517\n",
       " 1       2022-06-07       한 3만5천원이면 사볼만하긴 한데..  0.117217  0.856992\n",
       " 2       2022-06-07           어차피 자회사 무한 상장 ㅋㅋ  0.128808  0.013120\n",
       " 3       2022-06-07      ㅁㅊㄴ들! 이판국에 스톡옵션 추가상장?  0.140168  0.026343\n",
       " 4       2022-06-07        ■■■■■손절 유영두 어록■■■■■  0.496309  0.000000\n",
       " ...            ...                        ...       ...       ...\n",
       " 124448  2021-06-01                      아놔...  0.589211  0.064660\n",
       " 124449  2021-06-01           @@앞으로 개인의 글은 제목에  0.390372  0.037853\n",
       " 124450  2021-06-01             카카오~~~~~~~~~~~  0.760452  0.082566\n",
       " 124451  2021-06-01  내일 12만원대 마지막 매수 기회주는날이...  0.496573  1.000000\n",
       " 124452  2021-06-01  주식의 주자도 모르고 하면 역시 안되는구...  0.034682  0.688488\n",
       " \n",
       " [124453 rows x 4 columns])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "update_comment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0563725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_naver = pd.read_csv('./streamlit/data/feargreed_naver.csv')\n",
    "# df_kakao = pd.read_csv('./streamlit/data/feargreed_kakao.csv')\n",
    "# df_naver = df_naver[::-1].reset_index(drop=True)\n",
    "# df_kakao = df_kakao[::-1].reset_index(drop=True)\n",
    "# df_naver.to_csv('./streamlit/data/feargreed_naver_rev.csv',index=False)\n",
    "# df_kakao.to_csv('./streamlit/data/feargreed_kakao_rev.csv',index=False)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
