{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde6fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5550ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# LSTM 토크나이저\n",
    "with open('./src/lstm/goodtokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)  \n",
    "# LSTM 모델\n",
    "model = load_model('./src/lstm/goodmodel.h5')\n",
    "# BERT 토크나이저, 모델\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained('./src/bert', from_pt=True)\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained('./src/bert', from_pt=True)\n",
    "classifier = TextClassificationPipeline(tokenizer=loaded_tokenizer, model=loaded_model,\n",
    "                                            framework='tf', return_all_scores=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15f51b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(symbol):\n",
    "    krx = pd.read_csv('./src/krx_code.csv')\n",
    "    krx = krx.set_index('한글 종목약명')\n",
    "    try:\n",
    "        code = krx.at[symbol,'단축코드']\n",
    "        return code\n",
    "    except:\n",
    "        print('종목명을 다시 확인해주세요.')\n",
    "        return 0\n",
    "\n",
    "def get_comment(df,symbol):\n",
    "    code = get_code(symbol)\n",
    "    day = df['날짜'][0]\n",
    "    date_list = []\n",
    "    comment_list = []\n",
    "    raw_comment_list = []\n",
    "    chk = 1\n",
    "    i = 1\n",
    "    while chk:  \n",
    "        url = f'https://finance.naver.com/item/board.naver?code={code}&page={i}'\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50'}\n",
    "        res = requests.get(url, headers = headers)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')  \n",
    "        for j in range(20):\n",
    "            try:\n",
    "                root = bs.find('div',{'class':'section inner_sub'}).find_all('tr',{'onmouseover':'mouseOver(this)'})[j].text.split('\\n')                 \n",
    "                if day > root[1].split()[0].replace('.','-'):\n",
    "                    chk = 0\n",
    "                    break\n",
    "                if len(root) == 14: # 답글\n",
    "                    pass      \n",
    "                elif len(root) == 13: # 기본\n",
    "                    comment = root[3]\n",
    "                    date_list.append(root[1].split()[0].replace('.','-'))\n",
    "                    raw_comment_list.append(comment)            \n",
    "                else: # 에러\n",
    "                    pass\n",
    "            except: # 에러\n",
    "                pass\n",
    "            print(f'\\r{day} 댓글{len(raw_comment_list)}개 크롤링중..',end='')\n",
    "        i += 1\n",
    "        if chk == 0:\n",
    "            break   \n",
    "    print(f'\\r{day} 댓글{len(raw_comment_list)}개 크롤링완료')\n",
    "    df = pd.DataFrame()\n",
    "    df['날짜'] = date_list\n",
    "    df['댓글'] = raw_comment_list\n",
    "    return df\n",
    "\n",
    "def BERT_feargreed(df,symbol):\n",
    "    df = get_comment(df,symbol)  \n",
    "    raw_comment_list = df['댓글'].to_list()\n",
    "    pred_list=[]\n",
    "    for i in raw_comment_list:\n",
    "        a = classifier(i)[0]\n",
    "        f = a[0]['score']\n",
    "        g = a[1]['score']\n",
    "        if f >= g:\n",
    "            pred_list.append(1-f)\n",
    "        else:\n",
    "            pred_list.append(g)\n",
    "        print(f'\\rBERT 댓글{len(pred_list)}개 분석중..',end='')\n",
    "    df['BERT'] = pred_list  \n",
    "    return df\n",
    "\n",
    "def konlpy_okt(df,symbol):\n",
    "    df = BERT_feargreed(df,symbol)\n",
    "    okt = Okt()\n",
    "    tag_list = ['Noun','Verb','Adjective','VerbPrefix'] \n",
    "    comment_list = df['댓글'].to_list()\n",
    "    tokenized_data = []\n",
    "    for i in range(len(comment_list)):\n",
    "        tokenized_sentence = okt.pos(comment_list[i], stem=True) \n",
    "        tag_checked_sentence = []\n",
    "        for j in tokenized_sentence:\n",
    "            x,y = j\n",
    "            if y in tag_list:\n",
    "                tag_checked_sentence.append(x)\n",
    "        tokenized_data.append(tag_checked_sentence)     \n",
    "    for i in tokenized_data:\n",
    "        for j in range(len(i)):\n",
    "            i[j] = \"'\"+i[j]+\"'\"\n",
    "    df['LSTM'] = tokenized_data\n",
    "    return df\n",
    "    \n",
    "def feargreed_index(df,symbol):\n",
    "    df = konlpy_okt(df,symbol)\n",
    "    tokenized_data = df['LSTM'].to_list()\n",
    "    test = tokenizer.texts_to_sequences(tokenized_data)\n",
    "    test = pad_sequences(test, maxlen=15)\n",
    "    pred = model.predict(test)\n",
    "    df['LSTM'] = pred\n",
    "    df['LSTM'] = df['LSTM'].round(6)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c13a53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-04 댓글17개 크롤링완료.\n",
      "BERT 댓글17개 분석중.."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>댓글</th>\n",
       "      <th>BERT</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>증권사리포트 적정가</td>\n",
       "      <td>0.393901</td>\n",
       "      <td>0.989159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>도대체왜 걸어다니면서 담배피는거냐?니들은...</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>0.229988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>ㄲ ㅓ어어어어억 ㅋㅋ 금요일날포식 ㅋㅋㅋ</td>\n",
       "      <td>0.901422</td>\n",
       "      <td>0.005606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>대주전문가 김대주입니다</td>\n",
       "      <td>0.755341</td>\n",
       "      <td>0.876730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-04</td>\n",
       "      <td>안티들이 아직 많다는건?</td>\n",
       "      <td>0.300678</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32510</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>네이버 ㅋㅋㅋ</td>\n",
       "      <td>0.404388</td>\n",
       "      <td>0.014867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32511</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>역시 네이버가 갑 !!</td>\n",
       "      <td>0.803849</td>\n",
       "      <td>0.392791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32512</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>공매도 관련 전쟁 동영상 (한투연)</td>\n",
       "      <td>0.030869</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32513</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>네이버 분들 오세요!!</td>\n",
       "      <td>0.690160</td>\n",
       "      <td>0.119831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32514</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>네이버 주가예상 가즈아</td>\n",
       "      <td>0.617649</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32515 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               날짜                         댓글      BERT      LSTM\n",
       "0      2022-06-04                 증권사리포트 적정가  0.393901  0.989159\n",
       "1      2022-06-04  도대체왜 걸어다니면서 담배피는거냐?니들은...  0.055868  0.229988\n",
       "2      2022-06-04     ㄲ ㅓ어어어어억 ㅋㅋ 금요일날포식 ㅋㅋㅋ  0.901422  0.005606\n",
       "3      2022-06-04               대주전문가 김대주입니다  0.755341  0.876730\n",
       "4      2022-06-04              안티들이 아직 많다는건?  0.300678  0.000000\n",
       "...           ...                        ...       ...       ...\n",
       "32510  2021-06-01                    네이버 ㅋㅋㅋ  0.404388  0.014867\n",
       "32511  2021-06-01               역시 네이버가 갑 !!  0.803849  0.392791\n",
       "32512  2021-06-01        공매도 관련 전쟁 동영상 (한투연)  0.030869  0.000000\n",
       "32513  2021-06-01               네이버 분들 오세요!!  0.690160  0.119831\n",
       "32514  2021-06-01               네이버 주가예상 가즈아  0.617649  1.000000\n",
       "\n",
       "[32515 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./streamlit/data/feargreed_naver.csv')\n",
    "df2 = feargreed_index(df,'NAVER')\n",
    "df_naver = df2.append(df).drop_duplicates(subset=['날짜','댓글'],keep='last')\n",
    "df_naver = df_naver.reset_index(drop=True)\n",
    "df_naver.to_csv('./streamlit/data/feargreed_naver.csv',index=False)\n",
    "df_naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df1c936",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-04 댓글29개 크롤링완료.\n",
      "BERT 댓글16개 분석중.."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./streamlit/data/feargreed_kakao.csv')\n",
    "df2 = feargreed_index(df,'카카오')\n",
    "df_kakao = df2.append(df).drop_duplicates(subset=['날짜','댓글'],keep='last')\n",
    "df_kakao = df_kakao.reset_index(drop=True)\n",
    "df_kakao.to_csv('./streamlit/data/feargreed_kakao.csv',index=False)\n",
    "df_kakao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60422126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def konlpy_okt(df):\n",
    "#     okt = Okt()\n",
    "#     tag_list = ['Noun','Verb','Adjective','VerbPrefix'] \n",
    "#     comment_list = df['댓글'].to_list()\n",
    "#     tokenized_data = []\n",
    "#     for i in range(len(comment_list)):\n",
    "#         tokenized_sentence = okt.pos(str(comment_list[i]), stem=True) \n",
    "#         tag_checked_sentence = []\n",
    "#         for j in tokenized_sentence:\n",
    "#             x,y = j\n",
    "#             if y in tag_list:\n",
    "#                 tag_checked_sentence.append(x)\n",
    "#         tokenized_data.append(tag_checked_sentence)   \n",
    "#         print(f'\\r{i+1}개 형태소분리중',end='')\n",
    "#     for i in tokenized_data:\n",
    "#         for j in range(len(i)):\n",
    "#             i[j] = \"'\"+i[j]+\"'\"\n",
    "#     return tokenized_data\n",
    "    \n",
    "# def tokenize(df):\n",
    "#     tokenized_data = konlpy_okt(df)\n",
    "#     test = tokenizer.texts_to_sequences(tokenized_data)\n",
    "#     test = pad_sequences(test, maxlen=15)\n",
    "#     return test\n",
    "\n",
    "# def feargreed_indexx(df): \n",
    "#     test = tokenize(df)\n",
    "#     pred = model.predict(test)\n",
    "#     return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c4ba811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['LSTM'] = feargreed_indexx(df)\n",
    "# df['LSTM'] = df['LSTM'].round(6)\n",
    "# df = df.reset_index(drop=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "301be852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>댓글</th>\n",
       "      <th>BERT</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>강보합 가즈아</td>\n",
       "      <td>0.841521</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>NAVER 최저점262500원으로  제시...</td>\n",
       "      <td>0.011697</td>\n",
       "      <td>0.727272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>루나 충격 코인 시장 어디로 가나…오늘 ...</td>\n",
       "      <td>0.165881</td>\n",
       "      <td>0.222555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>하락장에서도 버티라</td>\n",
       "      <td>0.170349</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-06-02</td>\n",
       "      <td>'동반 추락' 네이버·카카오는 '바겐세일...</td>\n",
       "      <td>0.294569</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32291</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>네이버 ㅋㅋㅋ</td>\n",
       "      <td>0.404388</td>\n",
       "      <td>0.014867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32292</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>역시 네이버가 갑 !!</td>\n",
       "      <td>0.803849</td>\n",
       "      <td>0.392791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32293</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>공매도 관련 전쟁 동영상 (한투연)</td>\n",
       "      <td>0.030869</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32294</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>네이버 분들 오세요!!</td>\n",
       "      <td>0.690160</td>\n",
       "      <td>0.119831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32295</th>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>네이버 주가예상 가즈아</td>\n",
       "      <td>0.617649</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32296 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               날짜                         댓글      BERT      LSTM\n",
       "0      2022-06-02                    강보합 가즈아  0.841521  1.000000\n",
       "1      2022-06-02  NAVER 최저점262500원으로  제시...  0.011697  0.727272\n",
       "2      2022-06-02  루나 충격 코인 시장 어디로 가나…오늘 ...  0.165881  0.222555\n",
       "3      2022-06-02                 하락장에서도 버티라  0.170349  0.000000\n",
       "4      2022-06-02  '동반 추락' 네이버·카카오는 '바겐세일...  0.294569  0.000001\n",
       "...           ...                        ...       ...       ...\n",
       "32291  2021-06-01                    네이버 ㅋㅋㅋ  0.404388  0.014867\n",
       "32292  2021-06-01               역시 네이버가 갑 !!  0.803849  0.392791\n",
       "32293  2021-06-01        공매도 관련 전쟁 동영상 (한투연)  0.030869  0.000000\n",
       "32294  2021-06-01               네이버 분들 오세요!!  0.690160  0.119831\n",
       "32295  2021-06-01               네이버 주가예상 가즈아  0.617649  1.000000\n",
       "\n",
       "[32296 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./src/score_naver.csv')\n",
    "df['LSTM'] = df['LSTM'].round(6)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de36cbab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
