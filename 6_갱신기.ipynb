{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde6fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from transformers import TextClassificationPipeline\n",
    "from transformers import BertTokenizerFast\n",
    "from transformers import TFBertForSequenceClassification\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5550ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertForSequenceClassification: ['bert.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# LSTM 토크나이저\n",
    "with open('./src/lstm/tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)  \n",
    "# LSTM 모델\n",
    "model = load_model('./src/lstm/model.h5')\n",
    "# BERT 토크나이저, 모델\n",
    "loaded_tokenizer = BertTokenizerFast.from_pretrained('./src/bert', from_pt=True)\n",
    "loaded_model = TFBertForSequenceClassification.from_pretrained('./src/bert', from_pt=True)\n",
    "classifier = TextClassificationPipeline(tokenizer=loaded_tokenizer, model=loaded_model,\n",
    "                                            framework='tf', return_all_scores=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23990739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_code(symbol):\n",
    "    krx = pd.read_csv('./src/krx_code.csv')\n",
    "    krx = krx.set_index('한글 종목약명')\n",
    "    try:\n",
    "        code = krx.at[symbol,'단축코드']\n",
    "        return code\n",
    "    except:\n",
    "        print('종목명을 다시 확인해주세요.')\n",
    "        return 0\n",
    "\n",
    "def get_comment(df,symbol):\n",
    "    code = get_code(symbol)\n",
    "    day = df['날짜'][0]\n",
    "    date_list = []\n",
    "    comment_list = []\n",
    "    raw_comment_list = []\n",
    "    chk = 1\n",
    "    i = 1\n",
    "    while chk:  \n",
    "        url = f'https://finance.naver.com/item/board.naver?code={code}&page={i}'\n",
    "        headers = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36 Edg/100.0.1185.50'}\n",
    "        res = requests.get(url, headers = headers)\n",
    "        bs = BeautifulSoup(res.text, 'html.parser')  \n",
    "        for j in range(20):\n",
    "            try:\n",
    "                root = bs.find('div',{'class':'section inner_sub'}).find_all('tr',{'onmouseover':'mouseOver(this)'})[j].text.split('\\n')                 \n",
    "                if day > root[1].split()[0].replace('.','-'):\n",
    "                    chk = 0\n",
    "                    break\n",
    "                if len(root) == 14: # 답글\n",
    "                    pass      \n",
    "                elif len(root) == 13: # 기본\n",
    "                    comment = root[3]\n",
    "                    date_list.append(root[1].split()[0].replace('.','-'))\n",
    "                    raw_comment_list.append(comment)            \n",
    "                else: # 에러\n",
    "                    pass\n",
    "            except: # 에러\n",
    "                pass\n",
    "            print(f'\\r{day} 댓글{len(raw_comment_list)}개 크롤링중..',end='')\n",
    "        i += 1\n",
    "        if chk == 0:\n",
    "            break   \n",
    "    print(f'\\r{day} 댓글{len(raw_comment_list)}개 크롤링완료')\n",
    "    df = pd.DataFrame()\n",
    "    df['날짜'] = date_list\n",
    "    df['댓글'] = raw_comment_list\n",
    "    return df\n",
    "\n",
    "def BERT_feargreed(df,symbol):\n",
    "    df = get_comment(df,symbol)  \n",
    "    raw_comment_list = df['댓글'].to_list()\n",
    "    pred_list=[]\n",
    "    for i in raw_comment_list:\n",
    "        a = classifier(i)[0]\n",
    "        f = a[0]['score']\n",
    "        g = a[1]['score']\n",
    "        if f >= g:\n",
    "            pred_list.append(1-f)\n",
    "        else:\n",
    "            pred_list.append(g)\n",
    "        print(f'\\rBERT 댓글{len(pred_list)}개 분석중..',end='')\n",
    "    df['BERT'] = pred_list  \n",
    "    return df\n",
    "\n",
    "def konlpy_okt(df,symbol):\n",
    "    df = BERT_feargreed(df,symbol)\n",
    "    okt = Okt()\n",
    "    tag_list = ['Noun','Verb','Adjective','VerbPrefix'] \n",
    "    comment_list = df['댓글'].to_list()\n",
    "    tokenized_data = []\n",
    "    for i in range(len(comment_list)):\n",
    "        tokenized_sentence = okt.pos(comment_list[i], stem=True) \n",
    "        tag_checked_sentence = []\n",
    "        for j in tokenized_sentence:\n",
    "            x,y = j\n",
    "            if y in tag_list:\n",
    "                tag_checked_sentence.append(x)\n",
    "        tokenized_data.append(tag_checked_sentence)     \n",
    "    for i in tokenized_data:\n",
    "        for j in range(len(i)):\n",
    "            i[j] = \"'\"+i[j]+\"'\"\n",
    "    df['LSTM'] = tokenized_data\n",
    "    return df\n",
    "    \n",
    "def feargreed_index(df,symbol):\n",
    "    df = konlpy_okt(df,symbol)\n",
    "    tokenized_data = df['LSTM'].to_list()\n",
    "    test = tokenizer.texts_to_sequences(tokenized_data)\n",
    "    test = pad_sequences(test, maxlen=15)\n",
    "    pred = model.predict(test)\n",
    "    df['LSTM'] = pred\n",
    "    df['LSTM'] = df['LSTM'].round(6)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6afed5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-27 댓글82개 크롤링완료.\n",
      "BERT 댓글82개 분석중.."
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>댓글</th>\n",
       "      <th>BERT</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>경기도 찰수 아저씨</td>\n",
       "      <td>0.524800</td>\n",
       "      <td>0.041023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>개미굴 포착 ㅜㅜ</td>\n",
       "      <td>0.180544</td>\n",
       "      <td>0.004737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>27층 도착</td>\n",
       "      <td>0.585743</td>\n",
       "      <td>0.017785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>오른게 어디냐</td>\n",
       "      <td>0.182338</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-05-27</td>\n",
       "      <td>이년 매우 실망스럽네</td>\n",
       "      <td>0.004294</td>\n",
       "      <td>0.007721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7238</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>336000 고점 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ...</td>\n",
       "      <td>0.248269</td>\n",
       "      <td>0.002162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7239</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>네이버 올해 35 넘기쉽지않음</td>\n",
       "      <td>0.932359</td>\n",
       "      <td>0.028081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7240</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>여민수 전카카오 대표를 네이버대표로 모셔...</td>\n",
       "      <td>0.399360</td>\n",
       "      <td>0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7241</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>이런날 올라줘야지...뭔 34만만 가면 ...</td>\n",
       "      <td>0.445880</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7242</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>내가 네이버 손절한이유는 하나다</td>\n",
       "      <td>0.239418</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7243 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              날짜                         댓글      BERT      LSTM\n",
       "0     2022-05-27                 경기도 찰수 아저씨  0.524800  0.041023\n",
       "1     2022-05-27                  개미굴 포착 ㅜㅜ  0.180544  0.004737\n",
       "2     2022-05-27                     27층 도착  0.585743  0.017785\n",
       "3     2022-05-27                    오른게 어디냐  0.182338  0.999998\n",
       "4     2022-05-27                이년 매우 실망스럽네  0.004294  0.007721\n",
       "...          ...                        ...       ...       ...\n",
       "7238  2022-04-01  336000 고점 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ...  0.248269  0.002162\n",
       "7239  2022-04-01           네이버 올해 35 넘기쉽지않음  0.932359  0.028081\n",
       "7240  2022-04-01  여민수 전카카오 대표를 네이버대표로 모셔...  0.399360  0.000704\n",
       "7241  2022-04-01  이런날 올라줘야지...뭔 34만만 가면 ...  0.445880  0.999999\n",
       "7242  2022-04-01          내가 네이버 손절한이유는 하나다  0.239418  0.000000\n",
       "\n",
       "[7243 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./src/score_naver_0401.csv')\n",
    "df2 = feargreed_index(df,'NAVER')\n",
    "df_naver = df2.append(df).drop_duplicates(subset=['날짜','댓글'],keep='last')\n",
    "df_naver = df_naver.reset_index(drop=True)\n",
    "df_naver.to_csv('./src/score_naver_0501.csv',index=False)\n",
    "df_naver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d378b4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-27 댓글140개 크롤링완료.\n",
      "BERT 댓글118개 분석중.."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./src/score_kakao_0401.csv')\n",
    "df2 = feargreed_index(df,'카카오')\n",
    "df_kakao = df2.append(df).drop_duplicates(subset=['날짜','댓글'],keep='last')\n",
    "df_kakao = df_kakao.reset_index(drop=True)\n",
    "df_kakao.to_csv('./src/score_kakao_0401.csv',index=False)\n",
    "df_kakao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b042fdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60422126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4168개 형태소분리중"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>날짜</th>\n",
       "      <th>댓글</th>\n",
       "      <th>BERT</th>\n",
       "      <th>LSTM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>네이버 안망함에 한표.</td>\n",
       "      <td>0.194330</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>억지 주장이나 희망 사항이 아니고...</td>\n",
       "      <td>0.070530</td>\n",
       "      <td>0.000148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>아마존 16년만에 퐁낙♡</td>\n",
       "      <td>0.965886</td>\n",
       "      <td>0.003116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>아마존 14프로 폭ㅇ락</td>\n",
       "      <td>0.643351</td>\n",
       "      <td>0.000873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>애는주가가 왜 요 모냥이냐?  먼일 있는...</td>\n",
       "      <td>0.050652</td>\n",
       "      <td>0.000487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>336000 고점 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ...</td>\n",
       "      <td>0.248269</td>\n",
       "      <td>0.002162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>네이버 올해 35 넘기쉽지않음</td>\n",
       "      <td>0.932359</td>\n",
       "      <td>0.028081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>여민수 전카카오 대표를 네이버대표로 모셔...</td>\n",
       "      <td>0.399360</td>\n",
       "      <td>0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>이런날 올라줘야지...뭔 34만만 가면 ...</td>\n",
       "      <td>0.445880</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>2022-04-01</td>\n",
       "      <td>내가 네이버 손절한이유는 하나다</td>\n",
       "      <td>0.239418</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4168 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              날짜                         댓글      BERT      LSTM\n",
       "0     2022-04-30               네이버 안망함에 한표.  0.194330  0.000000\n",
       "1     2022-04-30      억지 주장이나 희망 사항이 아니고...  0.070530  0.000148\n",
       "2     2022-04-30              아마존 16년만에 퐁낙♡  0.965886  0.003116\n",
       "3     2022-04-30               아마존 14프로 폭ㅇ락  0.643351  0.000873\n",
       "4     2022-04-30  애는주가가 왜 요 모냥이냐?  먼일 있는...  0.050652  0.000487\n",
       "...          ...                        ...       ...       ...\n",
       "4163  2022-04-01  336000 고점 ㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋㅋ...  0.248269  0.002162\n",
       "4164  2022-04-01           네이버 올해 35 넘기쉽지않음  0.932359  0.028081\n",
       "4165  2022-04-01  여민수 전카카오 대표를 네이버대표로 모셔...  0.399360  0.000704\n",
       "4166  2022-04-01  이런날 올라줘야지...뭔 34만만 가면 ...  0.445880  0.999999\n",
       "4167  2022-04-01          내가 네이버 손절한이유는 하나다  0.239418  0.000000\n",
       "\n",
       "[4168 rows x 4 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def konlpy_okt(df):\n",
    "#     okt = Okt()\n",
    "#     tag_list = ['Noun','Verb','Adjective','VerbPrefix'] \n",
    "#     comment_list = df['댓글'].to_list()\n",
    "#     tokenized_data = []\n",
    "#     for i in range(len(comment_list)):\n",
    "#         tokenized_sentence = okt.pos(str(comment_list[i]), stem=True) \n",
    "#         tag_checked_sentence = []\n",
    "#         for j in tokenized_sentence:\n",
    "#             x,y = j\n",
    "#             if y in tag_list:\n",
    "#                 tag_checked_sentence.append(x)\n",
    "#         tokenized_data.append(tag_checked_sentence)   \n",
    "#         print(f'\\r{i+1}개 형태소분리중',end='')\n",
    "#     for i in tokenized_data:\n",
    "#         for j in range(len(i)):\n",
    "#             i[j] = \"'\"+i[j]+\"'\"\n",
    "#     return tokenized_data\n",
    "    \n",
    "# def tokenize(df):\n",
    "#     tokenized_data = konlpy_okt(df)\n",
    "#     test = tokenizer.texts_to_sequences(tokenized_data)\n",
    "#     test = pad_sequences(test, maxlen=15)\n",
    "#     return test\n",
    "\n",
    "# def feargreed_indexx(df): \n",
    "#     test = tokenize(df)\n",
    "#     pred = model.predict(test)\n",
    "#     return pred\n",
    "\n",
    "# df['LSTM'] = feargreed_indexx(df)\n",
    "# df['LSTM'] = df['LSTM'].round(6)\n",
    "# df = df.reset_index(drop=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cdb60c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
